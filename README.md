# OpenSanctions Learning Portfolio

This repository documents my learning and experimentation with web scraping, data processing, and building small crawlers in Python. It is meant to show my process, progress, and approach to problem-solving in a way that can be reviewed and understood by others.

## Current Projects

- `example_csv_crawler.py`: A crawler that fetches CSV data from public sources, parses it, and prints or processes the results.  
- Other experimental scripts and notes demonstrating my workflow and understanding of Python, HTTP requests, CSV handling, and basic data pipelines.

## Why I'm Doing This

I am building this portfolio to both learn and demonstrate my practical skills in data engineering.  
The goal is to create a traceable, iterative learning path, showing my thought process and ability to tackle real-world datasets, including those relevant to OpenSanctions.

## How I Work

I use AI-assisted tools such as GitHub Copilot, ChatGPT, and Phind to explore solutions and clarify concepts quickly.  
These tools accelerate learning, help me test ideas, and support writing maintainable code â€” but all work is understood and reviewed manually to ensure correctness.

## How to Run

```bash
python example_csv_crawler.py
```

This will fetch the CSV data, parse it, and print the first few rows, demonstrating basic crawler functionality.

## Notes

This is a learning-focused repository, primarily aimed at showing my approach and progress.
It is intended for review by the OpenSanctions team and anyone interested in my practical skills in data handling, web scraping, and Python development.

## Next Steps

Extend existing crawlers into full zavod-style scrapers for structured data ingestion.

Experiment with more complex datasets, including JSON and API-based sources.

Document lessons learned and improvements iteratively to show growth over time.