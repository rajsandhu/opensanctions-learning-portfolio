# OpenSanctions Dev Learning Repo

This is my personal playground for exploring **OpenSanctions** and learning how to work with their Python-based data pipelines and crawler tools.

I’m going through the datasets and crawler tasks step by step, trying to understand how the code works, how the data is structured, and how everything comes together. The goal is to build skills that would help me contribute to the project and eventually demonstrate readiness for a **Junior Data Engineer** role.

## What I’m doing here

- Running and experimenting with OpenSanctions crawlers.
- Testing Python data pipelines.
- Exploring and cleaning datasets.
- Learning to structure crawlers and write new ones for additional sources.

## How I’m learning

I’m using **LLM tools** (GitHub Copilot, ChatGPT, etc.) extensively — but not just to copy code.  
I use them in **dialogue**, asking questions, reasoning through errors, and deciding what changes to make.  
The goal is to actually understand how the workflows, crawlers, and data models work — not just reproduce examples.

## Notes

- This is a **learning repo**, so nothing here is production-ready.
- All Python scripts are run in a virtual environment.
- Data and archive folders are populated by running the crawlers locally.
- I’m keeping track of errors, fixes, and lessons learned in commits and issues, so anyone can see my progress.

## Disclaimer

I’m doing this to learn and document my process.  
This repo is **not affiliated with OpenSanctions**, but it uses their open-source framework for practice and exploration.
